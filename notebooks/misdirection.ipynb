{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misdirection\n",
    "\n",
    "Exploring IOI inputs with misdirected outputs - e.g.\n",
    "\n",
    "> John was two years older than Mary. Who was born first? Mary was born before\n",
    "\n",
    "This uses the same setup as the standard IOI task and can be measured in the same way, but allows us to compare any differences that exist between the activations for outputs that logically follow the input vs those that contradict it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.ioff()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NBVAL_IGNORE_OUTPUT\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below creates a set of IOI inputs with templated subject, indirect object and object variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "template = \"{0} was two years older than{1}. Who was born first,{2} was born before{3}\"\n",
    "names = (\" Mary\", \" John\", \" Alice\", \" Bob\")\n",
    "names = (\" Phil\", \" Bob\", \" James\", \" Paul\")\n",
    "\n",
    "prompts = [\n",
    "    template.format(S, IO, S, IO)\n",
    "    for S, IO in permutations(names, 2)\n",
    "]\n",
    "\n",
    "len(prompts), prompts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_prompts = [\n",
    "    template.format(S, IO, IO, S)\n",
    "    for S, IO in permutations(names, 2)\n",
    "]\n",
    "\n",
    "len(corrupted_prompts), corrupted_prompts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = run_prompts(model, *prompts)\n",
    "corrupted_cache = run_prompts(model, *corrupted_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, h = 3, 11\n",
    "attn_data = calculate_attns(cache, l, h)\n",
    "attn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_attn_data = calculate_attns(corrupted_cache, l, h)\n",
    "corrupted_attn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plot_attn(model, attn_data, feature_index=0, show_grid_labels=False)\n",
    "b = plot_attn(model, corrupted_attn_data, feature_index=0, show_grid_labels=False)\n",
    "c = plot_attn(model, attn_data, feature_index=3, show_grid_labels=False)\n",
    "d = plot_attn(model, corrupted_attn_data, feature_index=3, show_grid_labels=False)\n",
    "\n",
    "figure(a, b, c, d, title=\"Attention tokens for clean vs misdirected IOI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "corrupted_data = []\n",
    "for i in range(90, 144):\n",
    "    l, h = get_head_index(i)\n",
    "    attn_data = calculate_attns(cache, l, h)\n",
    "    corrupted_attn_data = calculate_attns(corrupted_cache, l, h)\n",
    "    data.append(attn_data)\n",
    "    corrupted_data.append(corrupted_attn_data)\n",
    "    a = plot_attn(model, attn_data, feature_index=0, show_grid_labels=False)\n",
    "    b = plot_attn(model, corrupted_attn_data, feature_index=0, show_grid_labels=False)\n",
    "    c = plot_attn(model, attn_data, feature_index=3, show_grid_labels=False)\n",
    "    d = plot_attn(model, corrupted_attn_data, feature_index=3, show_grid_labels=False)\n",
    "    fig = figure(a, b, c, d, title=f'Attention tokens for clean vs misdirected IOI ({l}.{h})')\n",
    "    fig.savefig(f'./images/attention_tokens_clean_vs_misdirected_IOI_{l}_{h}.png')\n",
    "\n",
    "data = torch.stack(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE plots for clean vs corrupted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token counts across input dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shared tokens across heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logit contribution heads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
