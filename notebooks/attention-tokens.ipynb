{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer, SVDInterpreter\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# NBVAL_IGNORE_OUTPUT\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from itertools import permutations, product\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "from rich import print\n",
    "from IPython.display import HTML\n",
    "from circuitsvis.attention import attention_heads\n",
    "from transformer_lens.utils import Slice\n",
    "from plotly import express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_head(cache, l, h, pos=None):\n",
    "    start, end = 0, len(cache['q', l][0])\n",
    "    if pos is not None:\n",
    "        start, end = pos\n",
    "    q = cache['q', l][:, start:end, h, :]\n",
    "    k = cache['k', l][:, start:end, h, :]\n",
    "    v = cache['v', l][:, start:end, h, :]\n",
    "    return torch.stack([q, k, v])\n",
    "\n",
    "def project_attn(cache, l, h, mlp=True, **kwargs):\n",
    "    OV = cache.model.OV[l, h]\n",
    "    mlp_in = model.W_in[l]\n",
    "    mlp_out = model.W_out[l]\n",
    "\n",
    "    cs = decompose_head(cache, l, h, **kwargs)\n",
    "    proj_A = torch.einsum('c b i h, d h -> c b i d', cs, OV.A)\n",
    "    proj_B = torch.einsum('c b i d, h d -> c b i d', proj_A, OV.B)\n",
    "    out = proj_B\n",
    "    if mlp:\n",
    "        mlped = torch.einsum('c b i d, d j -> c b i j', proj_B, mlp_in)\n",
    "        mlped_out = torch.einsum('c b i j, j d -> c b i d', mlped, mlp_out)\n",
    "        out = mlped_out\n",
    "    return out\n",
    "\n",
    "def head2logits(cache, l, h, **kwargs):\n",
    "    projections = project_attn(cache, l, h, **kwargs)\n",
    "    logits = cache.model.unembed(projections)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head2preds(cache, hp, l, h, k=1):\n",
    "    OV = cache.model.OV[l, h]\n",
    "    proj_A = torch.einsum('b n m h, d h -> b n m d', hp, OV.A)\n",
    "    proj_B = torch.einsum('b n m d, h d -> b n m d', proj_A, OV.B)\n",
    "    out = proj_B\n",
    "    logits = cache.model.unembed(out[0])\n",
    "    preds = torch.topk(logits, k, dim=-1).indices\n",
    "    return preds\n",
    "\n",
    "def parse_tokens(tokens):\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens[i])):\n",
    "            t = tokens[i][j]\n",
    "            if t == '\\n':\n",
    "                tokens[i][j] = '<nl>'\n",
    "            if t == ' ':\n",
    "                tokens[i][j] = '<sp>'\n",
    "            if t == '\\t':\n",
    "                tokens[i][j] = '<tab>'\n",
    "            if t == '<|endoftext|>':\n",
    "                tokens[i][j] = 'EOS'\n",
    "    return tokens\n",
    "\n",
    "def head_component_to_tokens(cache, layer, head, component, **kwargs):\n",
    "    preds = head2preds(cache, component, layer, head, **kwargs)\n",
    "    str_preds = parse_tokens([\n",
    "        cache.model.to_str_tokens(p) \n",
    "        for p in preds\n",
    "    ])\n",
    "    return str_preds\n",
    "\n",
    "def calculate_attention_tokens(cache, layer, head, hp, **kwargs):\n",
    "    str_preds = head_component_to_tokens(cache, layer, head, hp, **kwargs)\n",
    "\n",
    "    # Create a unique list of tokens, maintaining the order they first appear\n",
    "    unique_tokens = {}\n",
    "    for i in range(0, len(str_preds)):\n",
    "        for j in range(i + 1):\n",
    "            token = str_preds[i][j]\n",
    "            if token not in unique_tokens:\n",
    "                unique_tokens[token] = len(unique_tokens)\n",
    "    \n",
    "    sequence_length = len(str_preds)\n",
    "    \n",
    "    token_matrix = torch.full((sequence_length, sequence_length), -1).to(device)\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(i + 1):\n",
    "            token = str_preds[i][j]\n",
    "            token_matrix[i, j] = unique_tokens[token]\n",
    "\n",
    "    return token_matrix, unique_tokens\n",
    "\n",
    "def plot_attention_head(cache, layer, head, cmap=None, labels=True, **kwargs):\n",
    "    patterns = cache['attn', layer][:, head, :, :]\n",
    "    sequence_length = patterns.shape[-1]\n",
    "    pattern = patterns.mean(dim=0)\n",
    "    q, k, v = decompose_head(cache, layer, head)\n",
    "    hp = q.unsqueeze(2) * k.unsqueeze(1)\n",
    "    token_matrix, attention_tokens = calculate_attention_tokens(cache, layer, head, hp, **kwargs)\n",
    "    attention_token_labels = list(attention_tokens.keys())\n",
    "    q_str_preds = head_component_to_tokens(cache, layer, head, q.unsqueeze(1), **kwargs)\n",
    "    k_str_preds = head_component_to_tokens(cache, layer, head, k.unsqueeze(1), **kwargs)\n",
    "    v_str_preds = head_component_to_tokens(cache, layer, head, v.unsqueeze(1), **kwargs)\n",
    "\n",
    "    fig = px.imshow(\n",
    "        token_matrix.cpu(),\n",
    "        color_continuous_scale=cmap,\n",
    "        color_continuous_midpoint=0.5,\n",
    "        title=f'Attention head {head} at layer {layer}',\n",
    "    )\n",
    "\n",
    "    input_tokens = parse_tokens(\n",
    "        [cache.model.to_str_tokens(random.choice(cache.prompts))]\n",
    "    )[0]\n",
    "\n",
    "    min_opacity = 0.3\n",
    "    for i in range(sequence_length):\n",
    "        if labels:\n",
    "            fig.add_annotation(x=-1, y=i, text=input_tokens[i], showarrow=False, xshift=-15, yshift=0, font=dict(size=16, color='black'))\n",
    "            fig.add_annotation(x=sequence_length, y=i, text=v_str_preds[0][i], showarrow=False, xshift=15, yshift=0, font=dict(size=16, color='black'))\n",
    "            fig.add_annotation(x=i, y=sequence_length, text=input_tokens[i], textangle=45, showarrow=False, xshift=0, yshift=0, font=dict(size=16, color='black'))\n",
    "            fig.add_annotation(x=i, y=-1, text=q_str_preds[0][i], textangle=-45, showarrow=False, xshift=0, yshift=0, font=dict(size=16, color='black'))\n",
    "        for j in range(i + 1):\n",
    "            text = attention_token_labels[int(token_matrix[i, j].item())]\n",
    "            opacity = max(min(pattern[i, j].item() + min_opacity, 1), min_opacity)\n",
    "            if labels:\n",
    "                fig.add_annotation(\n",
    "                    x=j,\n",
    "                    y=i,\n",
    "                    text=text,\n",
    "                    textangle=-45,\n",
    "                    showarrow=False,\n",
    "                    font=dict(color=\"white\"),\n",
    "                    opacity=opacity,\n",
    "                )\n",
    "\n",
    "            if pattern[i, j] > min_opacity:\n",
    "                fig.add_shape(\n",
    "                    type=\"rect\",\n",
    "                    x0=j-0.5,\n",
    "                    y0=i-0.5,\n",
    "                    x1=j+0.5,\n",
    "                    y1=i+0.5,\n",
    "                    line=dict(color=\"white\", width=2),\n",
    "                    fillcolor=\"rgba(0, 0, 0, 0)\",\n",
    "                )\n",
    "    \n",
    "    fig.update_coloraxes(showscale=False)\n",
    "    fig.update_layout(\n",
    "        width=1200, height=800,\n",
    "        plot_bgcolor='white',\n",
    "        xaxis=dict(showticklabels=False),\n",
    "        yaxis=dict(showticklabels=False, autorange='reversed'),\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(model, *prompts):\n",
    "    print(f'Running prompt: {prompts}')\n",
    "    _, cache = model.run_with_cache(list(prompts))\n",
    "    cache.prompts = list(prompts)\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from ipywidgets import Dropdown, Output, VBox, HBox\n",
    "from IPython.display import display\n",
    "\n",
    "def create_image_gallery(plots):\n",
    "    dropdown = Dropdown(\n",
    "        options=[(f'Plot {i+1}', i) for i in range(len(plots))],\n",
    "        value=0,\n",
    "        description='Select Plot:',\n",
    "    )\n",
    "    output = Output()\n",
    "\n",
    "    def update_plot(change):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            plots[change['new']].show()\n",
    "\n",
    "    dropdown.observe(update_plot, names='value')\n",
    "    display(VBox([dropdown, output]))\n",
    "\n",
    "    # Initialize with the first plot\n",
    "    update_plot({'new': 0})\n",
    "\n",
    "    return output\n",
    "\n",
    "def compare_plots(*plots):\n",
    "    outputs = [Output() for _ in plots]\n",
    "\n",
    "    for out, plot in zip(outputs, plots):\n",
    "        with out:\n",
    "            plot.show()\n",
    "\n",
    "    display(HBox(outputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import HBox, Output, widgets\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def compare_plots(*plots, figure_layout={'width': 400, 'height': 300}):\n",
    "    # Initialize an HBox widget to hold all plots side by side\n",
    "    hbox = HBox(layout={'display': 'flex', 'flex_flow': 'row', 'align_items': 'stretch', 'width': '100%'})\n",
    "    \n",
    "    print(f'Plots: {len(plots)}')\n",
    "    for plot in plots:\n",
    "        # Create an output widget for each plot\n",
    "        out = Output()\n",
    "        with out:\n",
    "            # Apply layout adjustments to the plot\n",
    "            plot.update_layout(width=figure_layout['width'], height=figure_layout['height'])\n",
    "        \n",
    "        # Add the output widget to the HBox\n",
    "        hbox.children += (out,)\n",
    "\n",
    "    # Display the HBox with all plots\n",
    "    display(hbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown, Output, VBox, Layout\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def create_image_gallery(plots):\n",
    "    dropdown = Dropdown(\n",
    "        options=[(f'Plot {i+1}', i) for i in range(len(plots))],\n",
    "        value=0,\n",
    "        description='Select Plot:',\n",
    "    )\n",
    "    output = Output()\n",
    "\n",
    "    def update_plot(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)  # Clear the previous plot\n",
    "            # Directly display the selected plot\n",
    "            plots[change['new']].show()\n",
    "\n",
    "    dropdown.observe(update_plot, names='value')\n",
    "\n",
    "    # Initialize with the first plot\n",
    "    update_plot({'new': 0})\n",
    "\n",
    "    return VBox([dropdown, output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import HBox, Output, Layout\n",
    "from IPython.display import display\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def compare_plots(*plots, figure_layout={'width': 800, 'height': 500}):\n",
    "    outputs = [Output() for _ in plots]\n",
    "\n",
    "    for out, plot in zip(outputs, plots):\n",
    "        # Apply layout adjustments to each plot\n",
    "        plot.update_layout(width=figure_layout['width'], height=figure_layout['height'])\n",
    "        with out:\n",
    "            # Use IPython.display.display instead of plot.show()\n",
    "            display(plot)\n",
    "\n",
    "    # Set up a scrollable horizontal box layout\n",
    "    scrollable_layout = Layout(display='flex', flex_flow='row', overflow='scroll hidden', \n",
    "                               border='solid 1px', align_items='stretch', width='auto', height=f\"{figure_layout['height'] + 20}px\")\n",
    "\n",
    "    display(HBox(outputs, layout=scrollable_layout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import HBox, Layout\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def compare_plots(*plots, figure_layout={'width': 800, 'height': 500}):\n",
    "    # Convert Plotly figures to FigureWidgets with the desired layout\n",
    "    plot_widgets = [\n",
    "        go.FigureWidget(p.update_layout(width=figure_layout['width'], height=figure_layout['height'])) for p in plots\n",
    "    ]\n",
    "    \n",
    "    # Set up a horizontal box layout\n",
    "    hbox_layout = Layout(display='flex', flex_flow='row', overflow='scroll hidden', \n",
    "                         border='solid 1px', align_items='stretch', width='100%', height=f\"{figure_layout['height'] + 20}px\")\n",
    "    \n",
    "    # Create an HBox with the plot widgets\n",
    "    hbox = HBox(plot_widgets, layout=hbox_layout)\n",
    "    \n",
    "    # Display the HBox directly\n",
    "    display(hbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import HBox, Layout\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import Dropdown, VBox, Output\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import HBox, Layout\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "\n",
    "def compare_plots(*plots, figure_layout={'width': '800', 'height': '500'}):\n",
    "    widgets = []\n",
    "    \n",
    "    for plot in plots:\n",
    "        # Check if the plot is a Figure and convert it to FigureWidget for interactivity\n",
    "        if isinstance(plot, go.Figure):\n",
    "            plot = go.FigureWidget(plot)\n",
    "        plot.layout.width = figure_layout['width']\n",
    "        plot.layout.height = figure_layout['height']\n",
    "        widgets.append(plot)\n",
    "\n",
    "    # Create an HBox with the plot widgets\n",
    "    hbox = HBox(widgets, layout=Layout(display='flex', flex_flow='row', align_items='stretch'))\n",
    "    display(hbox)\n",
    "\n",
    "def create_image_gallery(plots):\n",
    "    dropdown = Dropdown(options=[(f'Plot {i+1}', i) for i in range(len(plots))], description='Select Plot:')\n",
    "    output = Output()\n",
    "    current_index = 0\n",
    "    \n",
    "    def update_plot(change):\n",
    "        nonlocal current_index\n",
    "        # Check if the function is being called post-initialization\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            current_index = change['new']\n",
    "            plots[change['new']].show()\n",
    "\n",
    "    dropdown.observe(update_plot, names='value')\n",
    "\n",
    "    gallery = VBox([dropdown, output])\n",
    "    return gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running prompt: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'The next sentence is a lie. The previous sentence is true.'</span>,<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Running prompt: \u001b[1m(\u001b[0m\u001b[32m'The next sentence is a lie. The previous sentence is true.'\u001b[0m,\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "repeat() got an unexpected keyword argument 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cache \u001b[38;5;241m=\u001b[39m run_prompt(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe next sentence is a lie. The previous sentence is true.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mplot_attention_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[98], line 65\u001b[0m, in \u001b[0;36mplot_attention_head\u001b[0;34m(cache, layer, head, cmap, labels, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m k_str_preds \u001b[38;5;241m=\u001b[39m head_component_to_tokens(cache, layer, head, k\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     63\u001b[0m v_str_preds \u001b[38;5;241m=\u001b[39m head_component_to_tokens(cache, layer, head, v\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhp\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToken matrix shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken_matrix\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[1;32m     69\u001b[0m     token_matrix\u001b[38;5;241m.\u001b[39mcpu(),\n\u001b[1;32m     70\u001b[0m     color_continuous_scale\u001b[38;5;241m=\u001b[39mcmap,\n\u001b[1;32m     71\u001b[0m     color_continuous_midpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     72\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttention head \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhead\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     73\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: repeat() got an unexpected keyword argument 'dim'"
     ]
    }
   ],
   "source": [
    "cache = run_prompt(model, \"The next sentence is a lie. The previous sentence is true.\")\n",
    "fig = plot_attention_head(cache, 0, 1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Comparing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> plots\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Comparing \u001b[1;36m2\u001b[0m plots\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "\n    Invalid value of type 'builtins.str' received for the 'width' property of layout\n        Received value: '800'\n\n    The 'width' property is a number and may be specified as:\n      - An int or float in the interval [10, inf]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompare_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m, in \u001b[0;36mcompare_plots\u001b[0;34m(figure_layout, *plots)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(plot, go\u001b[38;5;241m.\u001b[39mFigure):\n\u001b[1;32m     16\u001b[0m     plot \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigureWidget(plot)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m \u001b[38;5;241m=\u001b[39m figure_layout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m plot\u001b[38;5;241m.\u001b[39mlayout\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m figure_layout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m widgets\u001b[38;5;241m.\u001b[39mappend(plot)\n",
      "File \u001b[0;32m~/Work/layterz/experiments/venv/lib/python3.10/site-packages/plotly/basedatatypes.py:5926\u001b[0m, in \u001b[0;36mBaseLayoutType.__setattr__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   5923\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_subplot_re_match(prop)\n\u001b[1;32m   5924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5925\u001b[0m     \u001b[38;5;66;03m# Set as ordinary property\u001b[39;00m\n\u001b[0;32m-> 5926\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBaseLayoutHierarchyType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5928\u001b[0m     \u001b[38;5;66;03m# Set as subplotid property\u001b[39;00m\n\u001b[1;32m   5929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_subplotid_prop(prop, value)\n",
      "File \u001b[0;32m~/Work/layterz/experiments/venv/lib/python3.10/site-packages/plotly/basedatatypes.py:4930\u001b[0m, in \u001b[0;36mBasePlotlyType.__setattr__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   4917\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4918\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   4919\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4926\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m   4927\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prop\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, prop) \u001b[38;5;129;01mor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_props:\n\u001b[1;32m   4929\u001b[0m     \u001b[38;5;66;03m# Let known properties and private properties through\u001b[39;00m\n\u001b[0;32m-> 4930\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBasePlotlyType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4932\u001b[0m     \u001b[38;5;66;03m# Raise error on unknown public properties\u001b[39;00m\n\u001b[1;32m   4933\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_on_invalid_property_error()(prop)\n",
      "File \u001b[0;32m~/Work/layterz/experiments/venv/lib/python3.10/site-packages/plotly/graph_objs/_layout.py:4274\u001b[0m, in \u001b[0;36mLayout.width\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m   4272\u001b[0m \u001b[38;5;129m@width\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m   4273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwidth\u001b[39m(\u001b[38;5;28mself\u001b[39m, val):\n\u001b[0;32m-> 4274\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwidth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/Work/layterz/experiments/venv/lib/python3.10/site-packages/plotly/basedatatypes.py:5912\u001b[0m, in \u001b[0;36mBaseLayoutType.__setitem__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   5909\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_subplot_re_match(prop)\n\u001b[1;32m   5910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5911\u001b[0m     \u001b[38;5;66;03m# Set as ordinary property\u001b[39;00m\n\u001b[0;32m-> 5912\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBaseLayoutHierarchyType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5913\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5914\u001b[0m     \u001b[38;5;66;03m# Set as subplotid property\u001b[39;00m\n\u001b[1;32m   5915\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_subplotid_prop(prop, value)\n",
      "File \u001b[0;32m~/Work/layterz/experiments/venv/lib/python3.10/site-packages/plotly/basedatatypes.py:4874\u001b[0m, in \u001b[0;36mBasePlotlyType.__setitem__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   4870\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_array_prop(prop, value)\n\u001b[1;32m   4872\u001b[0m     \u001b[38;5;66;03m# ### Handle simple property ###\u001b[39;00m\n\u001b[1;32m   4873\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4874\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4876\u001b[0m     \u001b[38;5;66;03m# Make sure properties dict is initialized\u001b[39;00m\n\u001b[1;32m   4877\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_props()\n",
      "File \u001b[0;32m~/Work/layterz/experiments/venv/lib/python3.10/site-packages/plotly/basedatatypes.py:5218\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   5217\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   5220\u001b[0m \u001b[38;5;66;03m# val is None\u001b[39;00m\n\u001b[1;32m   5221\u001b[0m \u001b[38;5;66;03m# -----------\u001b[39;00m\n\u001b[1;32m   5222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5223\u001b[0m     \u001b[38;5;66;03m# Check if we should send null update\u001b[39;00m\n",
      "File \u001b[0;32m~/Work/layterz/experiments/venv/lib/python3.10/site-packages/plotly/basedatatypes.py:5213\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5210\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_validator(prop)\n\u001b[1;32m   5212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5213\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_coerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   5215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_invalid:\n",
      "File \u001b[0;32m~/Work/layterz/experiments/venv/lib/python3.10/site-packages/_plotly_utils/basevalidators.py:807\u001b[0m, in \u001b[0;36mNumberValidator.validate_coerce\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;66;03m# Check numeric\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, numbers\u001b[38;5;241m.\u001b[39mNumber):\n\u001b[0;32m--> 807\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_invalid_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;66;03m# Check min/max\u001b[39;00m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_min_max:\n",
      "File \u001b[0;32m~/Work/layterz/experiments/venv/lib/python3.10/site-packages/_plotly_utils/basevalidators.py:296\u001b[0m, in \u001b[0;36mBaseValidator.raise_invalid_val\u001b[0;34m(self, v, inds)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[1;32m    294\u001b[0m                 name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 296\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    297\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    Invalid value of type {typ} received for the '{name}' property of {pname}\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m        Received value: {v}\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m{valid_clr_desc}\"\"\"\u001b[39;00m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    302\u001b[0m                 name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    303\u001b[0m                 pname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_name,\n\u001b[1;32m    304\u001b[0m                 typ\u001b[38;5;241m=\u001b[39mtype_str(v),\n\u001b[1;32m    305\u001b[0m                 v\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(v),\n\u001b[1;32m    306\u001b[0m                 valid_clr_desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription(),\n\u001b[1;32m    307\u001b[0m             )\n\u001b[1;32m    308\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: \n    Invalid value of type 'builtins.str' received for the 'width' property of layout\n        Received value: '800'\n\n    The 'width' property is a number and may be specified as:\n      - An int or float in the interval [10, inf]"
     ]
    }
   ],
   "source": [
    "compare_plots(fig, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random token sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running prompt: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'John went to the river, to the bank, and to the beach.'</span>,<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Running prompt: \u001b[1m(\u001b[0m\u001b[32m'John went to the river, to the bank, and to the beach.'\u001b[0m,\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"John went to the river, to the bank, and to the beach.\"\n",
    "cache = run_prompt(model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots = []\n",
    "for i in range(0, 12):\n",
    "    for j in range(11, 12):\n",
    "        plots.append(\n",
    "            plot_attention_head(cache, i, j)\n",
    "        )\n",
    "\n",
    "len(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a258af7e34740a5a24029292780ecc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Select Plot:', options=(('Plot 1', 0), ('Plot 2', 1), ('Plot 3', 2), ('Pl…"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_image_gallery(plots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tim was born in 19\"\n",
    "cache = run_prompt(model, prompt)\n",
    "\n",
    "for i in range(0, 12):\n",
    "    for j in range(0, 12):\n",
    "        fig = plot_attention_head(cache, i, j, cmap='Viridis', labels=False)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pattern = torch.randint(0, 50257, (1, 1), device=device)\n",
    "prompt = base_pattern.repeat(1, 32)\n",
    "cache = run_prompt(model, model.to_string(prompt[0]))\n",
    "\n",
    "for i in range(0, 12):\n",
    "    for j in range(0, 12):\n",
    "        fig = plot_attention_head(cache, i, j, cmap='Viridis', labels=False)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pattern = torch.randint(0, 50257, (1, 4), device=device)\n",
    "prompt = base_pattern.repeat(1, 8)\n",
    "cache = run_prompt(model, model.to_string(prompt[0]))\n",
    "\n",
    "for i in range(0, 12):\n",
    "    for j in range(0, 12):\n",
    "        fig = plot_attention_head(cache, i, j, cmap='Viridis', labels=False)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pattern = torch.randint(0, 50257, (1, 4), device=device)\n",
    "mirrored_pattern = torch.cat((base_pattern, torch.flip(base_pattern, dims=[1])), dim=1)\n",
    "prompt = mirrored_pattern.repeat(1, 4)\n",
    "cache = run_prompt(model, model.to_string(prompt[0]))\n",
    "\n",
    "plot = make_subplots(rows=1, cols=2, subplot_titles=(\"Layer 0\", \"Layer 11\"))\n",
    "for i in range(0, 12):\n",
    "    fig = plot_attention_head(cache, 0, i, cmap='Viridis', labels=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pattern_1 = torch.randint(0, 50257, (1, 4), device=device)\n",
    "base_pattern_2 = torch.randint(0, 50257, (1, 4), device=device)\n",
    "prompt = torch.cat((base_pattern_1, base_pattern_2) * 4, dim=1)\n",
    "cache = run_prompt(model, model.to_string(prompt[0]))\n",
    "\n",
    "for l in range(0, 12):\n",
    "    fig = plot_attention_head(cache, 0, l, cmap='Viridis', labels=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikus = [\n",
    "    \"Amid lines of code, Patterns dance in torch's glow, Insight blooms, shared flow.\",\n",
    "    \"Digital quest shared, Silent tensors weave and merge, Clarity unfurls.\",\n",
    "    \"In code's embrace, thoughts Spin, seeking truth in patterns, Discovery's path.\",\n",
    "]\n",
    "\n",
    "prompt = ' '.join(haikus)\n",
    "cache = run_prompt(model, prompt)\n",
    "\n",
    "for l in range(0, 12):\n",
    "    for h in range(0, 12):\n",
    "        fig = plot_attention_head(cache, l, h, cmap='Viridis', labels=False)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Universality is a key hypothesis in mechanistic interpretability – that different models learn similar features and circuits when trained on similar task.\" \n",
    "cache = run_prompt(model, prompt)\n",
    "\n",
    "for l in range(0, 12):\n",
    "    for h in range(0, 12):\n",
    "        fig = plot_attention_head(cache, l, h, cmap='Viridis', labels=False)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open questions\n",
    "---\n",
    "\n",
    "- are head tokens consistent across inputs?\n",
    "- do head token counts remain consistent across inputs?\n",
    "  - plot graphs for this\n",
    "- which tokens are shared across all heads if any?\n",
    "- are shared tokens common across inputs?\n",
    "- how many tokens are used per row?\n",
    "\n",
    "improvements\n",
    "---\n",
    "- plot Q in the top diagonal\n",
    "- add border to cells over an attention score threshold\n",
    "- plot resid stream predictions\n",
    "- plot K instead of Q*K\n",
    "  - if useful, add diagonal for Q*K at current token\n",
    "- plot averaged inputs instead of individual prompts\n",
    "- plot grid of attention token graphs\n",
    "  - needs to run head calculations in parellel\n",
    "- craft prompt for gpt to analyse patterns in attention tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
